#!/bin/bash
# Description: Script that fetches Pokémon data in parallel using jobs command
# If an API request fails, implements a retry mechanism (up to 3 times)
# Usage: ./parallel_pokemon_fetcher.sh
# Requirements: curl, jq

API_BASE_URL="https://pokeapi.co/api/v2/pokemon/"
DEFAULT_POKEMON_LIST=("bulbasaur" "ivysaur" "venusaur" "charmander" "charmeleon")
OUTPUT_DIR="pokemon_data"
ERROR_LOG="errors.txt"
MAX_RETRIES=3
MAX_PARALLEL_PROCESSES=5  # Limit concurrent processes to avoid overwhelming the API

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# Cleanup function
cleanup() {
    # Remove empty output files if any
    find "$OUTPUT_DIR" -type f -empty -delete
    # Remove output directory if empty
    if [ -d "$OUTPUT_DIR" ] && [ -z "$(ls -A "$OUTPUT_DIR")" ]; then
        rmdir "$OUTPUT_DIR"
    fi
}
trap cleanup EXIT

# Function to check network connection
check_network_connection() {
    echo "Checking network connection..."
    if ! curl -s --head "$API_BASE_URL" | grep "200" > /dev/null; then
        echo "Error: Unable to connect to the Pokémon API. Please check your network connection." >&2
        exit 1
    fi
}

check_valid_pokemon_name() {
    local pokemon="$1"
    if ! curl -sSf "$API_BASE_URL/$pokemon" > /dev/null; then
        echo "Error: Invalid Pokémon name '$pokemon'. Please check the name and try again." >&2
        exit 1
    fi
}

# Function to fetch Pokémon data with retries
fetch_pokemon_data() {
    local pokemon="$1"
    local output_file="$OUTPUT_DIR/$(echo "$pokemon" | sed 's/^./\U&/').json"
    local retry_count=0
    local success=0
    
    while [[ $retry_count -lt $MAX_RETRIES ]]; do
        if curl -sSf "$API_BASE_URL/$pokemon" -o "$output_file"; then
            success=1
            break
        else
            retry_count=$((retry_count + 1))
            if [[ $retry_count -lt $MAX_RETRIES ]]; then
                sleep $((retry_count * 2))  # Exponential backoff
            fi
        fi
    done

    if [[ $success -eq 1 ]]; then
        echo "Successfully fetched data for $pokemon"
    else
        echo "Failed to fetch data for $pokemon after $MAX_RETRIES attempts" >> "$ERROR_LOG"
        rm -f "$output_file"  # Remove failed output file
    fi
}

# Main function to manage parallel fetching using jobs
fetch_pokemon_in_parallel() {
    local pokemon_list=("$@")
    local pids=()
    local running_processes=0
    
    # Check network connection before starting
    check_network_connection
    
    echo "Starting parallel fetch for ${#pokemon_list[@]} Pokémon..."
    
    for pokemon in "${pokemon_list[@]}"; do
        # Wait if we've reached max parallel processes
        while (( $(jobs -r | wc -l) >= MAX_PARALLEL_PROCESSES )); do
            # Check for completed processes
            for pid in "${pids[@]}"; do
                if ! kill -0 "$pid" 2>/dev/null; then
                    echo "Process $pid completed"
                    pids=("${pids[@]/$pid}")  # Remove completed PID
                    ((running_processes--))
                fi
            done
            sleep 1
        done
        
        # Start a new background process
        fetch_pokemon_data "$pokemon" &
        pids+=($!)  # Store the PID of the background job
        ((running_processes++))
        check_valid_pokemon_name "$pokemon"  # Validate Pokémon name before fetching
        echo "Started process for $pokemon"
    done
    
    # Wait for all remaining processes to complete
    wait
    echo "All processes completed"
}

# Main execution
fetch_pokemon_in_parallel "${DEFAULT_POKEMON_LIST[@]}"

# Exit with success status
exit 0